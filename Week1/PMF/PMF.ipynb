{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE5D-aHbi9f_"
      },
      "source": [
        "**Probabilistic Matrix Factorization** \n",
        "\n",
        "PMF란 Factorization 기법 중 하나로써 데이터의 값이 Guassian distribution을 따른다고 가정하는 것이 특징이다. 즉, 추천 시스템에서는 점수값 R이 Gaussian 분포를 따른다고 가정하는 것이다. 시간 복잡도를 낮추기 위하여 m x n 형태의 점수 행렬을 d x m 모양의 U 행렬, 그리고 d x n 형태의 V행렬로 factorization 시키게 된다. U와 V 역시 각각 정규분포를 따르게 구성한다. 그렇게 되면 기존에 m x n개의 element를 학습시켜야 했던 반면, factorization 이후에는 d x (m + n)개의 element들만 학습시키면 된다. d는 하이퍼 파라미터이기에 상수이다. 즉, pmf의 시간 복잡도는 linearly 증가하게 된다. 따라서, sparse하고 imbalanced한 datasets에 효과적인 기법이다. \n",
        "\n",
        "알고리즘은 다음과 같다.\n",
        "\n",
        "1. U, V 값을 d x m, 그리고 d x n 모양을 따르게 정규분포 값을 할당한다.\n",
        "2. U의 전치행렬과 V를 곱하여 R의 예측 값을 구한다.\n",
        "3. 실제 R값과 비교하고 역전파를 통해 U와 V를 학습시킨다.\n",
        "4. 3을 정해진 epoch만큼 반복한다. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjQ1Y0oUiz78",
        "outputId": "fd7f4705-5fbc-49c2-b148-5b4db2c023f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0, 8252.744\n",
            "Step 50, 2600.260\n",
            "Step 100, 1565.989\n",
            "Step 150, 1126.650\n",
            "Step 200, 940.850\n",
            "Step 250, 844.803\n",
            "Step 300, 786.246\n",
            "Step 350, 745.761\n",
            "Step 400, 715.755\n",
            "Step 450, 692.681\n",
            "Step 500, 674.285\n",
            "Step 550, 659.440\n",
            "Step 600, 646.908\n",
            "Step 650, 636.440\n",
            "Step 700, 627.467\n",
            "Step 750, 619.645\n",
            "Step 800, 612.851\n",
            "Step 850, 606.842\n",
            "Step 900, 601.589\n",
            "Step 950, 596.938\n",
            "Predictions: \n",
            " tensor([4., 2., 4., 4., 3., 5., 3., 4., 5., 3., 3., 5., 2., 4., 4., 3., 4., 3.,\n",
            "        3., 3., 5., 3., 3., 4., 3., 4., 3., 3., 5., 5., 3., 4., 5., 1., 3., 4.,\n",
            "        3., 3., 2., 5., 3., 3., 3., 5., 3., 5., 3.], grad_fn=<RoundBackward0>)\n",
            "Truth: \n",
            " tensor([4., 2., 4., 4., 3., 5., 3., 4., 5., 3., 3., 4., 2., 5., 4., 3., 4., 3.,\n",
            "        3., 3., 5., 3., 3., 4., 3., 5., 3., 3., 5., 5., 3., 4., 5., 1., 3., 4.,\n",
            "        3., 4., 2., 5., 3., 3., 3., 5., 3., 4., 3.])\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "ratings = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ratings.csv')\n",
        "ratings.describe()\n",
        "\n",
        "\n",
        "\n",
        "rating_matrix = ratings.pivot(index='userId', columns='movieId', values='rating')\n",
        "n_users, n_movies = rating_matrix.shape\n",
        "# Scaling ratings to between 0 and 1, this helps our model by constraining predictions\n",
        "min_rating, max_rating = ratings['rating'].min(), ratings['rating'].max()\n",
        "rating_matrix = (rating_matrix - min_rating) / (max_rating - min_rating)\n",
        "\n",
        "\n",
        "# Replacing missing ratings with -1 so we can filter them out later\n",
        "rating_matrix[rating_matrix.isnull()] = -1\n",
        "rating_matrix = torch.FloatTensor(rating_matrix.values)\n",
        "\n",
        "\n",
        "\n",
        "# This is how we can define our feature matrices\n",
        "# We're going to be training these, so we'll need gradients\n",
        "latent_vectors = 5\n",
        "user_features = torch.randn(n_users, latent_vectors, requires_grad=True)\n",
        "user_features.data.mul_(0.01)\n",
        "movie_features = torch.randn(n_movies, latent_vectors, requires_grad=True)\n",
        "movie_features.data.mul_(0.01)\n",
        "\n",
        "\n",
        "class PMFLoss(torch.nn.Module):\n",
        "    def __init__(self, lam_u=0.3, lam_v=0.3):\n",
        "        super().__init__()\n",
        "        self.lam_u = lam_u\n",
        "        self.lam_v = lam_v\n",
        "\n",
        "    def forward(self, matrix, u_features, v_features):\n",
        "        non_zero_mask = (matrix != -1).type(torch.FloatTensor)\n",
        "        predicted = torch.sigmoid(torch.mm(u_features, v_features.t()))\n",
        "\n",
        "        diff = (matrix - predicted) ** 2\n",
        "        prediction_error = torch.sum(diff * non_zero_mask)\n",
        "\n",
        "        u_regularization = self.lam_u * torch.sum(u_features.norm(dim=1))\n",
        "        v_regularization = self.lam_v * torch.sum(v_features.norm(dim=1))\n",
        "\n",
        "        return prediction_error + u_regularization + v_regularization\n",
        "\n",
        "criterion = PMFLoss()\n",
        "loss = criterion(rating_matrix, user_features, movie_features)\n",
        "\n",
        "# Actual training loop now\n",
        "\n",
        "latent_vectors = 30\n",
        "user_features = torch.randn(n_users, latent_vectors, requires_grad=True)\n",
        "user_features.data.mul_(0.01)\n",
        "movie_features = torch.randn(n_movies, latent_vectors, requires_grad=True)\n",
        "movie_features.data.mul_(0.01)\n",
        "\n",
        "pmferror = PMFLoss(lam_u=0.05, lam_v=0.05)\n",
        "optimizer = torch.optim.Adam([user_features, movie_features], lr=0.01)\n",
        "for step, epoch in enumerate(range(1000)):\n",
        "    optimizer.zero_grad()\n",
        "    loss = pmferror(rating_matrix, user_features, movie_features)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if step % 50 == 0:\n",
        "        print(f\"Step {step}, {loss:.3f}\")\n",
        "\n",
        "# Checking if our model can reproduce the true user ratings\n",
        "user_idx = 7\n",
        "user_ratings = rating_matrix[user_idx, :]\n",
        "true_ratings = user_ratings != -1\n",
        "predictions = torch.sigmoid(torch.mm(user_features[user_idx, :].view(1, -1), movie_features.t()))\n",
        "predicted_ratings = (predictions.squeeze()[true_ratings]*(max_rating - min_rating) + min_rating).round()\n",
        "actual_ratings = (user_ratings[true_ratings]*(max_rating - min_rating) + min_rating).round()\n",
        "\n",
        "print(\"Predictions: \\n\", predicted_ratings)\n",
        "print(\"Truth: \\n\", actual_ratings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R7mZ0I5lqrf",
        "outputId": "09e901ab-6e38-4571-ff9b-5fc5bf765e82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
